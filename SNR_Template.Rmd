---
title: "Simple Normal Regression Analysis"
author: "`r Sys.info()[['effective_user']]`"
date: "`r Sys.time()`"
output: 
  html_document:
    code_folding: hide
params:
  path_data: ""
  x: ""
  y: ""
  n_chains: 4
  n_iter: 10000
  ci_pct: 95
  n_lines: 200
  posterior_prob: !r c()
  posterior_predict: !r c()
  
---

# Parameters
1. Path to dataset: params$path_data
2. Independent Variable: params$x
3. Depedent Variable: params$y
4. Number of stan chains: params$n_chains
5. Number of chain iterations: params$n_iter
6. Percentage to use in Credible Interval: params$ci_pct
7. Number of lines to include on the output with all the sample lines: params$n_liness
8. Vector of relationships to calculate the posterior probability for (e.g. dependent variable > 1.2): params$posterior_prob
9. Vector of depdent variable values to predict indepdent variable values from (e.g. dependent variable = 5, what is potential model): params$posterior_predict

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rstanarm)
library(bayesplot)
library(reshape2)
library(janitor)
library(bayesrules)

dataset <- read.csv(params$path_data)

```


### Plot of variables of interest
```{r}

ggplot(dataset, aes_string(x = params$x, y = params$y)) + 
  geom_point()

```

### Building our model

```{r message=FALSE, results="hide"}
set.seed(84735)

## Convert character parameters to a formula

form <- as.formula(paste0(params$y, " ~ ", params$x))

## Pass that formula to normal_model_sim

normal_model_sim <- stan_glm(form, 
  data = dataset,
  family = gaussian,
  chains = params$n_chains,
  iter = params$n_iter)

```

### Diagnostics

```{r}

# Trace plots of parallel chains
mcmc_trace(normal_model_sim, size = 0.1)

# Density plots of parallel chains
mcmc_dens_overlay(normal_model_sim)
```

### Posterior Summary Statistics

```{r}
# Posterior summary statistics
model_summary <- summary(normal_model_sim)
head(as.data.frame(model_summary), -2)
```

best guess for regression equation:


### Credible Interval

```{r}
if (params$ci_pct > 1) {
  frac <- params$ci_pct / 100
} else {
  frac <- params$ci_pct
}

posterior_interval(normal_model_sim, prob = frac)
```

```{r}
# Shade in the 90% CI. For example:
mcmc_areas(normal_model_sim,
  pars = c(params$x),
  prob = frac,
  point_est = "mean"
)
```

### Practice Q1: part g

Creating a dataframe where the chains for each parameter are in one column

```{r}
normal_model_df <- as.array(normal_model_sim) %>%
  melt() %>%
  pivot_wider(names_from = parameters, values_from = value)
```


### Practice Q1: part h

plotting the first 20 regression lines with the posterior mean regression line overlayed in blue
```{r}
first_20 <- head(normal_model_df, 20)
intercept <- model_summary[1][1]
slope <- model_summary[2][1]

# ggplot(params$data, aes(x = params$x, y = params$y)) +
#   geom_point(size = 0.1) +
#   geom_abline(
#     data = first_20,
#     aes(
#       intercept = `(Intercept)`,
#       # issue here: have to access the x variable from the first_20 df not main df?
#       slope = first_20[4]
#       ),
#     color = "orange", alpha = .8, size = 0.1
#   )+
#   geom_abline(aes(intercept = intercept, slope = slope),
#     color = "blue"
#   )
```

We can also do this with first 200

```{r}
first_200 <- head(normal_model_df, 200)

# ggplot(params$data, aes(x = params$x, y = params$y)) +
#   geom_point(size = 0.1) +
#   geom_abline(
#     data = first_200,
#     aes(
#       intercept = `(Intercept)`,
#       slope = first_20[4]
#     ),
#     color = "orange", alpha = .8, size = 0.1
#   ) +
#   geom_abline(aes(intercept = intercept, slope = slope),
#     color = "blue"
#   )
```


### Practice Q1: part i
Finding posterior probability that beta1>0

```{r}
# conditions <- c(">8", "<=10", ">5")
# a solution would  be to create a function for vectorizing

normal_model_df %>%
  mutate(exceeds_0 = params$x > 0) %>%
  tabyl(exceeds_0)
```


### Practice Q1: part j (the non stan way)

make posterior predictions for when the temp is 58 (vector here) degrees
```{r}
# set.seed(84735)
# predict_z <- normal_model_df %>%
#   mutate(y_trend = `(Intercept)` + params$x*58) %>%
#   mutate(y_new = rnorm(20000, y_trend, sigma))
```


visualizing posterior y trend and posterior predictions when temp is 58:
```{r}
# ggplot(predict_58, aes(x = y_trend)) +geom_density()
#
# ggplot(predict_58, aes(x = y_new)) +geom_density()
```

### Practice Q1: part j (the stan way)

let's use stan functions for posterior prediction!

We'll make a prediction for 72 degrees!
```{r}
# set.seed(84735)
# shortcut_prediction <-
#   posterior_predict(normal_model_sim,
#                     newdata = data.frame(temp_actual = 72))
```

let's look at the denisty of posterior predictions
```{r}
# mcmc_dens(shortcut_prediction) +
# labs(x = "predicted ridership on a 72 degree day")
```





# To-Do:

1. Set up posterior probability/posterior prediction section. These should both be able to accept a vector of things to run. For probability, something of the form c(">8", "<=10", ">5") and for prediction, of the form c(82, 35, 90).
2. Add a section from the Evaluating Regression Models lecture (Ch 10) for the posterior predictive check and potentially cross validation.
3. Add in interpretations of output that are based on the output numbers in cases where they're possible.
4. Make the output pretty!
5. Write a function that runs this file!! Should require data, x, and y but everything else should be optional with good defaults.
