---
title: "Simple Normal Regression Analysis"
author: "`r Sys.info()[['effective_user']]`"
date: "`r Sys.time()`"
output: 
  html_document:
    code_folding: hide
params:
  data: !r tibble()
  x: ""
  y: ""
  n_chains: 4
  n_iter: 10000
  ci_pct: 95
  n_lines: 0
  posterior_prob: !r c()
  posterior_predict: !r c()
  n_folds: 10
  
---

# Parameters
1. Data: params$data
2. Independent Variable: params$x
3. Depedent Variable: params$y
4. Number of stan chains: params$n_chains
5. Number of chain iterations: params$n_iter
6. Percentage to use in Credible Interval: params$ci_pct
7. Number of lines to include on the output with all the sample lines: params$n_liness
8. Vector of relationships to calculate the posterior probability for (e.g. dependent variable > 1.2): params$posterior_prob
9. Vector of depdent variable values to predict indepdent variable values from (e.g. dependent variable = 5, what is potential model): params$posterior_predict

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rstanarm)
library(bayesplot)
library(reshape2)
library(janitor)
library(bayesrules)

```

```{r, echo = FALSE}
# Define CV function

prediction_summary_cv <- function(data, model, k = 10, prob_inner = 0.5, prob_outer = 0.95){
  
      # Split data into k possibly unequal folds
      # https://gist.github.com/dsparks/3695362
      random_draw <- rnorm(nrow(data))
      k_quantiles <- quantile(random_draw, 0:k/k)
      folds <- cut(random_draw, k_quantiles, include.lowest = TRUE)
      levels(folds) <- 1:k
      data <- data %>% 
                mutate(fold = sample(folds, size = length(folds), replace = FALSE))
      y <- model$terms[[2]]
          
      # Test the model on each one of the k folds
      folds <- data.frame()
      for(i in 1:k){
        
         data_train <- data %>% 
           filter(fold != i) %>% 
           dplyr::select(-fold)
         
        data_test <- data %>% 
           filter(fold == i) %>% 
           dplyr::select(-fold)
        
        model_train <- update(model, data = data_train, refresh = FALSE)
        
        predictions_test <- posterior_predict(model_train, newdata = data_test)
        
        folds <- rbind(folds,
                       prediction_summary(y = c(as.matrix((data_test %>% select(y))[,1])),
                                          yrep = predictions_test))
        }
          
      # Calculate the cross validated error
      cv <- folds %>% 
        summarize_all(mean)
      
      folds <- data.frame(fold = 1:k, folds)
      
      
      return(list(folds = folds, cv = cv))
}

```


### Plot of variables of interest
```{r}

ggplot(params$data, aes_string(x = params$x, y = params$y)) + 
  geom_point(color = "#00134A") +
  ggtitle(paste0(params$y, " vs. ", params$x))

```

### Building our model

```{r message=FALSE, results="hide"}
set.seed(84735)

## Convert character parameters to a formula

form <- as.formula(paste0(params$y, " ~ ", params$x))

## Pass that formula to normal_model_sim

normal_model_sim <- stan_glm(form, 
  data = params$data,
  family = gaussian,
  chains = params$n_chains,
  iter = params$n_iter)

```

### Diagnostics

```{r}

# Trace plots of parallel chains
mcmc_trace(normal_model_sim, size = 0.1)

# Density plots of parallel chains
mcmc_dens_overlay(normal_model_sim)
```

### Posterior Summary Statistics

```{r}
# Posterior summary statistics
model_summary <- summary(normal_model_sim)
head(as.data.frame(model_summary), -2)
```

best guess for regression equation:


### Credible Interval

```{r}
if (params$ci_pct > 1) {
  frac <- params$ci_pct / 100
} else {
  frac <- params$ci_pct
}

posterior_interval(normal_model_sim, prob = frac)
```

```{r}
# Shade in the 90% CI. For example:
mcmc_areas(normal_model_sim,
  pars = c(params$x),
  prob = frac,
  point_est = "mean"
)
```

### Restructuring the dataframe

```{r}
normal_model_df <- as.array(normal_model_sim) %>%
  melt() %>%
  pivot_wider(names_from = parameters, values_from = value)
```


### Plotting potential regression lines from model

```{r}


if(params$n_lines == 0){
  num_lines <- round(nrow(params$data)/4)
}else{
  num_lines <- params$n_lines
}

first_n <- head(normal_model_df, num_lines)
intercept <- model_summary[1][1]
slope <- model_summary[2][1]

ggplot(params$data, aes_string(x = params$x, y = params$y)) +
  geom_point(size = 0.1) +
  geom_abline(
    data = first_n,
    aes_string(
      intercept = "`(Intercept)`",
      # issue here: have to access the x variable from the first_20 df not main df?
      slope = params$x
      ),
    color = "#CADDEC", alpha = .8, size = 0.1
  )+
  geom_abline(aes(intercept = intercept, slope = slope),
    color = "#00134A"
  )
```




```{r, echo = length(params$posterior_prob)>0, eval = length(params$posterior_prob)>0}

knitr::asis_output("### Posterior probability")
  
for(condition in params$posterior_prob){
  to_eval <- parse(text = paste0(params$x, condition))
  
  output <- normal_model_df %>%
  mutate(fits_condition = eval(to_eval)) %>%
  tabyl(fits_condition)
  print(paste0("Probability that ", params$y, " ", condition, " = ", output$percent[2]))
}



```




```{r, echo = length(params$posterior_predict)>0, eval = length(params$posterior_predict)>0}
knitr::asis_output("### Posterior predictions")

set.seed(84735)

for(prediction in params$posterior_predict){
  to_eval <- parse(text = paste0(params$x, " = ", prediction))
  shortcut_prediction <- posterior_predict(
  normal_model_sim,
  newdata = data.frame(eval(to_eval)))

  plot <- mcmc_dens(shortcut_prediction) +
  labs(x = paste0("Predicted ", params$y, " when ", params$x, " = ", prediction))
  
  print(plot)
}

```



### Evaluating Prediction Quality


#### Posterior Predictive Check

```{r}
set.seed(84735)
pp_check(normal_model_sim, nreps = 50)
```

#### Posterior Prediction Intervals

```{r}
set.seed(84735)

predictions <- posterior_predict(normal_model_sim,
  newdata = data)

dataset <- params$data

to_eval <- paste0("ppc_intervals(dataset$", params$y, ", yrep = predictions, x = ", "dataset$", params$x, ", prob = 0.5, prob_outer = 0.95)")

eval(parse(text = to_eval))
```


#### Cross Validation

```{r, message = FALSE}
set.seed(84735)

cv_procedure <- prediction_summary_cv(data = params$data,
                                      model = normal_model_sim,
                                      k = params$n_folds)

cv_procedure$cv
```


# To-Do:

1. Add in interpretations of output that are based on the output numbers in cases where they're possible. (And also add in text that describes what each graph is showing!)
2. Make the output pretty!
3. README + sample output HTMLs
4. See if we can accept things like x = temp_feel instead of x = "temp_feel"
