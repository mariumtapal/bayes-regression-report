---
title: "Simple Normal Regression Analysis"
author: "`r Sys.info()[['effective_user']]`"
date: "`r Sys.time()`"
output: 
  html_document:
    code_folding: hide
params:
  data: !r tibble()
  x: ""
  y: ""
  n_chains: 4
  n_iter: 10000
  ci_pct: 95
  n_lines: 0
  posterior_prob: !r c()
  posterior_predict: !r c()
  n_folds: 10
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 100)
library(tidyverse)
library(rstanarm)
library(bayesplot)
library(reshape2)
library(janitor)
library(bayesrules)


if(params$n_lines == 0){
  num_lines_display <- round(nrow(params$data)/4)
}else{
  num_lines_display <- params$n_lines
}
```


### Inputs

#### Data: 

```{r, echo = FALSE}
str(params$data)
```

#### Independent Variable (X): `r params$x`

#### Depedent Variable (Y): `r params$y`

#### Number Of Stan Chains: `r params$n_chains`

#### Number Of Iterations Per Chain: `r params$n_iter`

#### Credible Interval Percentage: `r params$ci_pct`

#### Number Of Potential Regression Lines To Graph: `r num_lines_display`


```{r, eval = length(params$posterior_prob)> 0 , echo = FALSE}
knitr::asis_output("#### Conditions To Check Posterior Probability Of (For Y Variable):")

params$posterior_prob

```



```{r, eval = length(params$posterior_predict)> 0, echo = FALSE}
knitr::asis_output("#### Values For X With Which To Predict Posterior Distributions Of Y: ")

params$posterior_predict

```

#### Number Of Folds To Use With Cross-Validation: `r params$n_folds`


```{r, echo = FALSE}
# Define CV function

prediction_summary_cv <- function(data, model, k = 10, prob_inner = 0.5, prob_outer = 0.95){
  
      # Split data into k possibly unequal folds
      # https://gist.github.com/dsparks/3695362
      random_draw <- rnorm(nrow(data))
      k_quantiles <- quantile(random_draw, 0:k/k)
      folds <- cut(random_draw, k_quantiles, include.lowest = TRUE)
      levels(folds) <- 1:k
      data <- data %>% 
                mutate(fold = sample(folds, size = length(folds), replace = FALSE))
      y <- model$terms[[2]]
          
      # Test the model on each one of the k folds
      folds <- data.frame()
      for(i in 1:k){
        
         data_train <- data %>% 
           filter(fold != i) %>% 
           dplyr::select(-fold)
         
        data_test <- data %>% 
           filter(fold == i) %>% 
           dplyr::select(-fold)
        
        model_train <- update(model, data = data_train, refresh = FALSE)
        
        predictions_test <- posterior_predict(model_train, newdata = data_test)
        
        folds <- rbind(folds,
                       prediction_summary(y = c(as.matrix((data_test %>% select(y))[,1])),
                                          yrep = predictions_test))
        }
          
      # Calculate the cross validated error
      cv <- folds %>% 
        summarize_all(mean)
      
      folds <- data.frame(fold = 1:k, folds)
      
      
      return(list(folds = folds, cv = cv))
}

```


### Plot of variables of interest
```{r}

ggplot(params$data, aes_string(x = params$x, y = params$y)) + 
  geom_point(color = "#00134A") +
  ggtitle(paste0(params$y, " vs. ", params$x))

```

### Building our model

```{r message=FALSE, results="hide", class.source = "fold-show"}
set.seed(84735)

## Convert character parameters to a formula

form <- as.formula(paste0(params$y, " ~ ", params$x))

## Pass that formula to normal_model_sim

normal_model_sim <- stan_glm(form, 
  data = params$data,
  family = gaussian,
  chains = params$n_chains,
  iter = params$n_iter)

```


### Diagnostics

```{r}

# Trace plots of parallel chains
mcmc_trace(normal_model_sim, size = 0.1)

# Density plots of parallel chains
mcmc_dens_overlay(normal_model_sim)
```

### Posterior Summary Statistics

Below are the summary statistics for the posterior of our simple normal regression model.

The main columns to pay attention to are:

1. mean
2. n_eff
3. Rhat

```{r}
# Posterior summary statistics
model_summary <- summary(normal_model_sim)
head(as.data.frame(model_summary), -2)
```

```{r, echo = FALSE}
df <- head(as.data.frame(model_summary), -2)
intercept <- df[[1]][1]
slope <- df[[1]][2]
Rhats <- df[[8]]
n_effs <- df[[7]]

if(slope > 0){
  slope <- paste0("+ ", as.character(slope))
}else if(slope < 0) {
  slope <- paste0("- ", as.character(abs(slope)))
}else{
  slope <- paste("+ ", as.character(slope))
}

```


#### Best Guess For Regression Equation ('mean'):

$$\hat{\text{`r params$y`}} = `r intercept` `r slope` * \text{`r params$x`}$$


#### Number of Effective Iterations ('n_eff'):

N_eff quantifies the number of independent samples it would take to produce an equivalently accurate posterior approximation as created by the Stan model.

We should be suspicious of the quality of our model if N_eff is less than 10% of the number of iterations run by our model.

```{r, echo = FALSE}
n_effs_pretty <- df[7]

n <- (params$n_iter * params$n_chains)

n_effs_flag <- n_effs_pretty %>%
  mutate(`Suspicious?` = n_eff/n < 0.1)

row.names(n_effs_flag) <- c("(Intercept)", params$x, "sigma")

n_effs_flag
```



#### Variability Across vs Within Chains ('Rhat'):

Rhat measures the ratio between:

1. The combined variability in our parameter across all chains, and
2. The typical variability within any individual chain.

Rhat values $\approx$ 1 indicate **stability** across chains, while Rhat values > 1 indicate **instability**.

The Rhat values for the provided model are:

```{r, echo = FALSE}
Rhats_pretty <- df[8]
Rhats <- df[[8]]

Rhats_flagged <- Rhats_pretty %>% 
  mutate(`Unstable?` = Rhat > 1.05)

row.names(Rhats_flagged) <- c("(Intercept)", params$x, "sigma")

Rhats_flagged
```



### Credible Interval

```{r}
if (params$ci_pct > 1) {
  frac <- params$ci_pct / 100
} else {
  frac <- params$ci_pct
}

posterior_interval(normal_model_sim, prob = frac)
```

```{r}
# Shade in the 90% CI. For example:
mcmc_areas(normal_model_sim,
  pars = c(params$x),
  prob = frac,
  point_est = "mean"
)
```

### Restructuring the dataframe

```{r}
normal_model_df <- as.array(normal_model_sim) %>%
  melt() %>%
  pivot_wider(names_from = parameters, values_from = value)
```


### Plotting potential regression lines from model

```{r}


if(params$n_lines == 0){
  num_lines <- round(nrow(params$data)/4)
}else{
  num_lines <- params$n_lines
}

first_n <- head(normal_model_df, num_lines)
intercept <- model_summary[1][1]
slope <- model_summary[2][1]

ggplot(params$data, aes_string(x = params$x, y = params$y)) +
  geom_point(size = 0.1) +
  geom_abline(
    data = first_n,
    aes_string(
      intercept = "`(Intercept)`",
      # issue here: have to access the x variable from the first_20 df not main df?
      slope = params$x
      ),
    color = "#CADDEC", alpha = .8, size = 0.1
  )+
  geom_abline(aes(intercept = intercept, slope = slope),
    color = "#00134A"
  )
```




```{r, echo = length(params$posterior_prob)>0, eval = length(params$posterior_prob)>0}

knitr::asis_output("### Posterior probability")
  
for(condition in params$posterior_prob){
  to_eval <- parse(text = paste0(params$x, condition))
  
  output <- normal_model_df %>%
  mutate(fits_condition = eval(to_eval)) %>%
  tabyl(fits_condition)
  print(paste0("Probability that ", params$y, " ", condition, " = ", output$percent[2]))
}



```




```{r, echo = length(params$posterior_predict)>0, eval = length(params$posterior_predict)>0}
knitr::asis_output("### Posterior predictions")

set.seed(84735)

for(prediction in params$posterior_predict){
  to_eval <- parse(text = paste0(params$x, " = ", prediction))
  shortcut_prediction <- posterior_predict(
  normal_model_sim,
  newdata = data.frame(eval(to_eval)))

  plot <- mcmc_dens(shortcut_prediction) +
  labs(x = paste0("Predicted ", params$y, " when ", params$x, " = ", prediction))
  
  print(plot)
}

```



### Evaluating Prediction Quality


#### Posterior Predictive Check

```{r}
set.seed(84735)
pp_check(normal_model_sim, nreps = 50)
```

#### Posterior Prediction Intervals

```{r}
set.seed(84735)

predictions <- posterior_predict(normal_model_sim,
  newdata = data)

dataset <- params$data

to_eval <- paste0("ppc_intervals(dataset$", params$y, ", yrep = predictions, x = ", "dataset$", params$x, ", prob = 0.5, prob_outer = 0.95)")

eval(parse(text = to_eval))
```


#### Cross Validation

```{r, message = FALSE}
set.seed(84735)

cv_procedure <- prediction_summary_cv(data = params$data,
                                      model = normal_model_sim,
                                      k = params$n_folds)

cv_procedure$cv
```


# To-Do:

1. Add in interpretations of output that are based on the output numbers in cases where they're possible. (And also add in text that describes what each graph is showing!)
2. Make the output pretty!
3. README + sample output HTMLs
4. See if we can accept things like x = temp_feel instead of x = "temp_feel"
