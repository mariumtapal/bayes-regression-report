---
title: "Simple Normal Regression Analysis"
author: "`r Sys.info()[['effective_user']]`"
date: "`r Sys.time()`"
output: html_document
params:
  data: !r tibble()
  x: ""
  y: ""
  n_chains: 4
  n_iter: 10000
  ci_pct: 95
  n_lines: 0
  posterior_prob: !r c()
  posterior_predict: !r c()
  n_folds: 10
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(scipen = 100)
library(tidyverse)
library(rstanarm)
library(bayesplot)
library(reshape2)
library(janitor)
library(bayesrules)
library(kableExtra)


if(params$n_lines == 0){
  num_lines_display <- round(nrow(params$data)/4)
}else{
  num_lines_display <- params$n_lines
}
```


### Inputs

#### Data: 

```{r, echo = FALSE}
str(params$data)
```

#### Independent Variable (X): `r params$x`

#### Depedent Variable (Y): `r params$y`

#### Number Of Stan Chains: `r params$n_chains`

#### Number Of Iterations Per Chain: `r params$n_iter`

#### Credible Interval Percentage: `r params$ci_pct`

#### Number Of Potential Regression Lines To Graph: `r num_lines_display`


```{r, eval = length(params$posterior_prob)> 0 , echo = FALSE}
knitr::asis_output("#### Conditions To Check Posterior Probability Of (For Y Variable):")

params$posterior_prob

```



```{r, eval = length(params$posterior_predict)> 0, echo = FALSE}
knitr::asis_output("#### Values For X With Which To Predict Posterior Distributions Of Y: ")

params$posterior_predict

```

#### Number Of Folds To Use With Cross-Validation: `r params$n_folds`


```{r, echo = FALSE}
# Define CV function

prediction_summary_cv <- function(data, model, k = 10, prob_inner = 0.5, prob_outer = 0.95){
  
      # Split data into k possibly unequal folds
      # https://gist.github.com/dsparks/3695362
      random_draw <- rnorm(nrow(data))
      k_quantiles <- quantile(random_draw, 0:k/k)
      folds <- cut(random_draw, k_quantiles, include.lowest = TRUE)
      levels(folds) <- 1:k
      data <- data %>% 
                mutate(fold = sample(folds, size = length(folds), replace = FALSE))
      y <- model$terms[[2]]
          
      # Test the model on each one of the k folds
      folds <- data.frame()
      for(i in 1:k){
        
         data_train <- data %>% 
           filter(fold != i) %>% 
           dplyr::select(-fold)
         
        data_test <- data %>% 
           filter(fold == i) %>% 
           dplyr::select(-fold)
        
        model_train <- update(model, data = data_train, refresh = FALSE)
        
        predictions_test <- posterior_predict(model_train, newdata = data_test)
        
        folds <- rbind(folds,
                       prediction_summary(y = c(as.matrix((data_test %>% select(y))[,1])),
                                          yrep = predictions_test))
        }
          
      # Calculate the cross validated error
      cv <- folds %>% 
        summarize_all(mean)
      
      folds <- data.frame(fold = 1:k, folds)
      
      
      return(list(folds = folds, cv = cv))
}

```


### Plot of variables of interest
```{r}

ggplot(params$data, aes_string(x = params$x, y = params$y)) + 
  geom_point(color = "#00134A") +
  ggtitle(paste0(params$y, " vs. ", params$x))

```

### Building our model

```{r message=FALSE, results="hide", class.source = "fold-show"}
set.seed(84735)

## Convert character parameters to a formula

form <- as.formula(paste0(params$y, " ~ ", params$x))

## Pass that formula to normal_model_sim

normal_model_sim <- stan_glm(form, 
  data = params$data,
  family = gaussian,
  chains = params$n_chains,
  iter = params$n_iter)

```


### Diagnostics

#### Trace Plots

```{r}
# Trace plots of parallel chains
mcmc_trace(normal_model_sim, size = 0.1)
```

#### Chain Density Overlay Plots

```{r}
# Density plots of parallel chains
mcmc_dens_overlay(normal_model_sim)
```



### Posterior Summary Statistics

Below are the summary statistics for the posterior of our simple normal regression model.


```{r, echo = FALSE}
# Posterior summary statistics
model_summary <- summary(normal_model_sim)
output <- head(as.data.frame(model_summary), -2)

output %>%
  kable(booktabs = T) %>%
  kable_styling() 
```

The main columns to pay attention to are:

1. mean
2. n_eff
3. Rhat

Using these three columns, we can determine the *average* regression equation across all of our iterations (using 'mean') as well as get a sense of whether or not the chains produced an accurate estimate of the posterior (using 'n_eff' and 'Rhat').


```{r, echo = FALSE}
df <- head(as.data.frame(model_summary), -2)
intercept <- df[[1]][1]
slope <- df[[1]][2]
Rhats <- df[[8]]
n_effs <- df[[7]]

if(slope > 0){
  slope <- paste0("+ ", as.character(slope))
}else if(slope < 0) {
  slope <- paste0("- ", as.character(abs(slope)))
}else{
  slope <- paste("+ ", as.character(slope))
}

```


#### Best Guess For Regression Equation ('mean'):

$$\hat{\text{`r params$y`}} = `r intercept` `r slope` * \text{`r params$x`}$$


#### Number of Effective Iterations ('n_eff'):

N_eff quantifies the number of independent samples it would take to produce an equivalently accurate posterior approximation as created by the Stan model.

We should be **suspicious** of the quality of our model if N_eff is less than 10% of the number of iterations run by our model across all of its chains.

**In the table below, parameters for which suspicious values of n_eff were found are highlighted red. If NO rows are red, then your model is likely okay in terms of its number of effective iterations!**

```{r, echo = FALSE}
n_effs_pretty <- df[7]

n <- (params$n_iter * params$n_chains)

n_effs_flag <- n_effs_pretty %>%
  mutate(n_iterations = n) %>%
  mutate(ratio = n_eff / n_iterations) %>%
  mutate(`Suspicious?` = n_eff/n < 0.1)

row.names(n_effs_flag) <- c("(Intercept)", params$x, "sigma")

color.me <- which(n_effs_flag$`Suspicious?` == TRUE)

n_effs_flag %>%
  kable(booktabs = T) %>%
  kable_styling() %>%
  row_spec(color.me, bold = T, color = "red")
```



#### Variability Across vs Within Chains ('Rhat'):

Rhat measures the ratio between:

1. The combined variability in our parameter across all chains, and
2. The typical variability within any individual chain.

Rhat values $\approx$ 1 indicate **stability** across chains, while Rhat values > 1 indicate **instability**.


**In the table below, parameters for which suspicious values of Rhat were found are highlighted red. If NO rows are red, then your model is likely okay in terms its chain variability ratio!**


```{r, echo = FALSE}
Rhats_pretty <- df[8]
Rhats <- df[[8]]

Rhats_flagged <- Rhats_pretty %>% 
  mutate(`Unstable?` = Rhat > 1.05)

row.names(Rhats_flagged) <- c("(Intercept)", params$x, "sigma")

color.me <- which(Rhats_flagged$`Unstable?` == TRUE)

Rhats_flagged %>% 
  kable(booktabs = T) %>%
  kable_styling() %>%
  row_spec(color.me, bold = T, color = "red")

```


### Credible Interval

Below we see `r params$ci_pct`% Credible Intervals for the posterior distribution of our three parameters: the intercept, slope, and the standard deviation of our data around the proposed regression line.

```{r}
if (params$ci_pct > 1) {
  frac <- params$ci_pct / 100
} else {
  frac <- params$ci_pct
}

posterior_interval(normal_model_sim, prob = frac) %>%
  kable(booktabs = T) %>%
  kable_styling() 
```

```{r, fig.show = 'hold', out.width = "30%"}
# Shade in the CI. For example:

mcmc_areas(normal_model_sim,
  pars = "(Intercept)",
  prob = frac,
  point_est = "mean"
) + labs(title = "(Intercept)")

mcmc_areas(normal_model_sim,
  pars = c(params$x),
  prob = frac,
  point_est = "mean"
) + labs(title = params$x)

mcmc_areas(normal_model_sim,
  pars = "sigma",
  prob = frac,
  point_est = "mean"
) + labs(title = "sigma")



```


### Plot of Potential Regression Lines Determined By Model

```{r}

# Restructuring the data frame
normal_model_df <- as.array(normal_model_sim) %>%
  melt() %>%
  pivot_wider(names_from = parameters, values_from = value)


if(params$n_lines == 0){
  num_lines <- round(nrow(params$data)/4)
}else{
  num_lines <- params$n_lines
}

first_n <- head(normal_model_df, num_lines)
intercept <- model_summary[1][1]
slope <- model_summary[2][1]

ggplot(params$data, aes_string(x = params$x, y = params$y)) +
  geom_point(size = 0.1) +
  geom_abline(
    data = first_n,
    aes_string(
      intercept = "`(Intercept)`",
      # issue here: have to access the x variable from the first_20 df not main df?
      slope = params$x
      ),
    color = "#CADDEC", alpha = .8, size = 0.1
  )+
  geom_abline(aes(intercept = intercept, slope = slope),
    color = "#00134A"
  )
```




```{r, echo = length(params$posterior_prob)>0, eval = length(params$posterior_prob)>0}

knitr::asis_output("### Posterior probability")
  
for(condition in params$posterior_prob){
  to_eval <- parse(text = paste0(params$x, condition))
  
  output <- normal_model_df %>%
  mutate(fits_condition = eval(to_eval)) %>%
  tabyl(fits_condition)
  print(paste0("Probability that ", params$y, " ", condition, " = ", output$percent[2]))
}



```




```{r, echo = length(params$posterior_predict)>0, eval = length(params$posterior_predict)>0}
knitr::asis_output("### Posterior predictions")

set.seed(84735)

for(prediction in params$posterior_predict){
  to_eval <- parse(text = paste0(params$x, " = ", prediction))
  shortcut_prediction <- posterior_predict(
  normal_model_sim,
  newdata = data.frame(eval(to_eval)))

  plot <- mcmc_dens(shortcut_prediction) +
  labs(x = paste0("Predicted ", params$y, " when ", params$x, " = ", prediction))
  
  print(plot)
}

```



### Evaluating Prediction Quality


#### Posterior Predictive Check

```{r}
set.seed(84735)
pp_check(normal_model_sim, nreps = 50)
```

#### Posterior Prediction Intervals

```{r}
set.seed(84735)

predictions <- posterior_predict(normal_model_sim,
  newdata = data)

dataset <- params$data

to_eval <- paste0("ppc_intervals(dataset$", params$y, ", yrep = predictions, x = ", "dataset$", params$x, ", prob = 0.5, prob_outer = 0.95)")

eval(parse(text = to_eval))
```


#### Cross Validation

```{r, message = FALSE}
set.seed(84735)

cv_procedure <- prediction_summary_cv(data = params$data,
                                      model = normal_model_sim,
                                      k = params$n_folds)

cv_procedure$cv %>%
  kable(booktabs = T) %>%
  kable_styling() 
```


# To-Do:

1. Add in interpretations of output that are based on the output numbers in cases where they're possible. (And also add in text that describes what each graph is showing!)
2. Make the output pretty!
3. README + sample output HTMLs
4. See if we can accept things like x = temp_feel instead of x = "temp_feel"
